{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "weighted-pursuit",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-tribute",
   "metadata": {},
   "source": [
    "### Large Ratio of Nulls\n",
    "Drop variables that have a high percent missing values\n",
    "Missing values can be converted to feature, depending on feature.\n",
    "Example: Primary language spoken if doesn't speak English. Na's can be converted to 'Speaks English'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-slovak",
   "metadata": {},
   "source": [
    "### Amount of Variation\n",
    "Drop or review variables that have a very low variation. They won't provide value to model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-lesson",
   "metadata": {},
   "source": [
    "### Pairwise Correlations\n",
    "Corelated variables are redundant and one can be dropped without loss of much information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-tower",
   "metadata": {},
   "source": [
    "### Correlation with the Target\n",
    "Drop variables that have a very low correlation with the target. \n",
    "Be mindful of features that have an effect when used together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-killer",
   "metadata": {},
   "source": [
    "### Forward/Backward/Stepwise Selection\n",
    "#### Forward Selection\n",
    "1. Identify the best variable\n",
    "2. Add the next best variable into the model\n",
    "3. And so on until some predefined criteria is met.\n",
    "\n",
    "#### Backward Elimination\n",
    "1. Start with all variables included in the model.\n",
    "2. Drop the least useful variable (based on the smallest drop in model accuracy)\n",
    "3. And so on until some predefined criteria is met.\n",
    "\n",
    "#### Stepwise Selection\n",
    "Similar to foward selectino process, but a variable can also be dropped if it's deemed as not useful any more after a certain number of steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-wallace",
   "metadata": {},
   "source": [
    "### LASSO\n",
    "Least Absolute Shrinkage and Selection Operator\n",
    "Two birds, one stone: variable selection + regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-programming",
   "metadata": {},
   "source": [
    "### Tree-Based\n",
    "Forests of trees to evaluate the importance of features\n",
    "\n",
    "Fit a number of randomized decision trees on various sub-samples of the dataset and use averaging to rank order features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team 107 Capstone Project",
   "language": "python",
   "name": "team_107_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
