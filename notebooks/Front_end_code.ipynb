{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "precise-border",
   "metadata": {},
   "source": [
    "# Code for Front-End\n",
    "These are the necessary code snippets to get the model working. The model was trained and saved so we no longer need to load any training or testing data and we can make predictions on the loaded model. \n",
    "\n",
    "The data for the predictions will need to be transformed (one-hot encoding and scaling) to make them work with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-reform",
   "metadata": {},
   "source": [
    "## Load Libs and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# instantiate model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# load model\n",
    "model.load_model(('../models/model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-october",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns order, group by type\n",
    "## X are features collected by Heroku. This code block will work if the data collected by Heroku is in the correct datatype. \n",
    "## Data from Heroku may need to be changed to different datatype depending on how that works.\n",
    "cat_cols = list(X.select_dtypes('category').columns)\n",
    "int_cols = list(X.select_dtypes(int).columns)\n",
    "flt_cols = list(X.select_dtypes(float).columns)\n",
    "num_cols = int_cols + flt_cols\n",
    "cols_order = num_cols + cat_cols\n",
    "X = X[cols_order]\n",
    "\n",
    "# Instatiate transformers\n",
    "ohe = OneHotEncoder()\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Define feature transformer process\n",
    "col_xformer = make_column_transformer(\n",
    "    (ohe, cat_cols),\n",
    "    (ss, num_cols),\n",
    "    remainder='passthrough')\n",
    "\n",
    "# This line of code will transform the features to the necessary format to be ingested by the model.\n",
    "## The model should be in the same format and structure as the dataframe that was used to train it.\n",
    "X_transformed = col_xformer.fit_transform(X)  # X in this case are the feature responses collected by Heroku, and re-ordered by the first code snippet in this cell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team 107 Capstone Project",
   "language": "python",
   "name": "team_107_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
