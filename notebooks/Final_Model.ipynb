{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "noticed-commitment",
   "metadata": {},
   "source": [
    "## Import Libs & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "british-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import accuracy_score, make_scorer, roc_auc_score, accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facial-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/model_baseline/baseline_hispanic_blk.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-irrigation",
   "metadata": {},
   "source": [
    "## Original DF Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "diagnostic-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into X and y and drop columns with nulls\n",
    "y = df.EOWN_ST\n",
    "X = (df\n",
    "     .dropna(axis='columns')\n",
    "     .drop('EOWN_ST', axis='columns')\n",
    "    )\n",
    "\n",
    "# Change cat features to cat dtype\n",
    "X[X.filter(regex='^E+.*').columns] = (X\n",
    "                                      .filter(regex='^E+.*')\n",
    "                                      .astype('category')\n",
    "                                     )\n",
    "\n",
    "# Drop recode columns\n",
    "drop_cols = X.filter(regex='^R+.*').columns\n",
    "X = X.drop(drop_cols, axis='columns')\n",
    "\n",
    "# Rearrange columns order, group by type\n",
    "cat_cols = list(X.select_dtypes('category').columns)\n",
    "int_cols = list(X.select_dtypes(int).columns)\n",
    "flt_cols = list(X.select_dtypes(float).columns)\n",
    "num_cols = int_cols + flt_cols\n",
    "cols_order = num_cols + cat_cols\n",
    "X = X[cols_order]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "looking-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into X and y and drop columns with nulls\n",
    "y = df.EOWN_ST\n",
    "X = (df\n",
    "     .dropna(axis='columns')\n",
    "     .drop('EOWN_ST', axis='columns')\n",
    "    )\n",
    "\n",
    "# Change cat features to cat dtype\n",
    "X[X.filter(regex='^E+.*').columns] = (X\n",
    "                                      .filter(regex='^E+.*')\n",
    "                                      .astype('category')\n",
    "                                     )\n",
    "\n",
    "# Drop recode columns\n",
    "drop_cols = X.filter(regex='^R+.*').columns\n",
    "X = X.drop(drop_cols, axis='columns')\n",
    "\n",
    "# Rearrange columns order, group by type\n",
    "cat_cols = list(X.select_dtypes('category').columns)\n",
    "int_cols = list(X.select_dtypes(int).columns)\n",
    "flt_cols = list(X.select_dtypes(float).columns)\n",
    "num_cols = int_cols + flt_cols\n",
    "cols_order = num_cols + cat_cols\n",
    "X = X[cols_order]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-amber",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "applicable-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ss = StandardScaler()\n",
    "\n",
    "col_xformer = make_column_transformer(\n",
    "    (ohe, cat_cols),\n",
    "    (ss, num_cols),\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-vessel",
   "metadata": {},
   "source": [
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "scheduled-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = col_xformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "motivated-murray",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign categorical column index to variable\n",
    "cat_cols_index = np.arange(18, 35, 1)\n",
    "\n",
    "# Resample with SMOTE+ENN\n",
    "smote_enn = SMOTEENN(smote=SMOTENC(random_state=23, categorical_features=cat_cols_index))\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-czech",
   "metadata": {},
   "source": [
    "## XGBoost Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "animated-yemen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=9,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.9,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign hyperparameters to a variable\n",
    "params = {'verbosity': 0,\n",
    "          'subsample': 0.9,\n",
    "          'min_child_weight': 1,\n",
    "          'max_depth': 9,\n",
    "          'gamma': 0.0,\n",
    "          'colsample_bytree': 0.8}\n",
    "\n",
    "# Instantiate XGB\n",
    "model = XGBClassifier(verbosity=0, \n",
    "                      subsample=0.9,\n",
    "                      min_child_weight=1,\n",
    "                      max_depth=9,\n",
    "                      gamma=0.0,\n",
    "                      colsample_bytree=0.8,\n",
    "                     )\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "valued-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('../models/model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-reconstruction",
   "metadata": {},
   "source": [
    "## Export to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "minimal-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "graduate-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/model_xgb_arthur.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-export",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team 107 Capstone Project",
   "language": "python",
   "name": "team_107_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
