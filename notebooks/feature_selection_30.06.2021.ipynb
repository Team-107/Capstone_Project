{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tough-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mounted-morrison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49704, 2127)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sipp_2018 = pd.read_csv('../data/interim/sipp2018_person/sipp2018_person.csv')\n",
    "sipp_2018.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-emerald",
   "metadata": {},
   "source": [
    "## Feature Engineering/Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "least-python",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     14293\n",
       "6     14176\n",
       "9      9524\n",
       "5      6000\n",
       "10     4955\n",
       "8       756\n",
       "Name: EEDUC_X, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collapse eeduc categories\n",
    "\n",
    "m1 = {5:[31,32,33,34,35,36,37,38], \n",
    "      6:[39],\n",
    "      7:[40,41,42],\n",
    "      8:[45],\n",
    "      9:[43],\n",
    "      10:[44,46],\n",
    "     }\n",
    "m2 = {v: k for k,vv in m1.items() for v in vv}\n",
    "m2\n",
    "sipp_2018['EEDUC_X'] = (sipp_2018\n",
    "                        .EEDUC\n",
    "                        .map(m2)\n",
    "                        .astype('category')\n",
    "                       )\n",
    "sipp_2018.EEDUC_X.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "residential-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Independent and Target Features \n",
    "y = sipp_2018.EOWN_ST\n",
    "X = sipp_2018.drop(['SSUID', 'PNUM', 'EOWN_ST'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlike-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-initial",
   "metadata": {},
   "source": [
    "# Univariate Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-league",
   "metadata": {},
   "source": [
    "## Percent Missing Values\n",
    "* Drop variables that have a high ratio of missing values.\n",
    "* Create binary indicators to denote miss (or non-missing) values.\n",
    "* Review of visualize variables with high ratio of missing values.\n",
    "***\n",
    "#### Thresholds\n",
    "* \\> 95% Discard\n",
    "* 50% - 95% No Imputation\n",
    "* \\< 50% Impute\n",
    "\n",
    "*Other sources recommend discarding nulls above ~65%*\n",
    "\n",
    "Missing values may also be converted or imputed, depending on variable. <br>\n",
    "**Example:** Primary language spoken if respondent doesn't speak English. Na's can be converted to 'Speaks English'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "governing-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TJB6_MSUMALT</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EJB6_TYPPAY1</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TJB1_WKSUM5</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TJB2_WKSUM5</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TJB3_WKSUM5</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EHLTHSAV1</th>\n",
       "      <td>0.724291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOCCDEBTVAL</th>\n",
       "      <td>0.723009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCBYR_3</th>\n",
       "      <td>0.721827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELIFEYN</th>\n",
       "      <td>0.711792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTHR401VAL</th>\n",
       "      <td>0.702336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1619 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              percent_missing\n",
       "TJB6_MSUMALT         1.000000\n",
       "EJB6_TYPPAY1         1.000000\n",
       "TJB1_WKSUM5          1.000000\n",
       "TJB2_WKSUM5          1.000000\n",
       "TJB3_WKSUM5          1.000000\n",
       "...                       ...\n",
       "EHLTHSAV1            0.724291\n",
       "TOCCDEBTVAL          0.723009\n",
       "TCBYR_3              0.721827\n",
       "ELIFEYN              0.711792\n",
       "TTHR401VAL           0.702336\n",
       "\n",
       "[1619 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return df with all features with % missing values more than 70%\n",
    "desc = X_train.describe().T\n",
    "desc = (desc\n",
    "        .assign(percent_missing = 1 - (desc['count'] / len(X_train)))\n",
    "        .percent_missing\n",
    "        .sort_values(ascending=False)\n",
    "        .to_frame()\n",
    "        .query('percent_missing > .7')\n",
    "       )\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-subdivision",
   "metadata": {},
   "source": [
    "**Review High NaN Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ranking-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Metadata\n",
    "sipp_dict_1 = pd.read_csv('../data/raw/sipp_2018/sippdict_1_of_2.csv')\n",
    "sipp_dict_2 = pd.read_csv('../data/raw/sipp_2018/sippdict_2_of_2.csv')\n",
    "sipp_dict = (pd.concat([sipp_dict_1, sipp_dict_2])\n",
    "             .set_index('Variable')\n",
    "             [['Description', 'Topic','Response Code']]\n",
    "            )\n",
    "# Inner Join High NaN with metadata dict\n",
    "high_nan_metadata = pd.merge(sipp_dict, desc, left_index=True, right_index=True, how='inner')\n",
    "high_nan_metadata.to_csv('../data/interim/sipp2018_person/FOR_REVIEW_high_NaN_features.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-professor",
   "metadata": {},
   "source": [
    "**Drop Features w/ High % Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "infectious-thunder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (39763, 506)\n",
      "X_test shape: (9941, 506)\n"
     ]
    }
   ],
   "source": [
    "high_nan_features = list(desc.T.columns)\n",
    "\n",
    "# Transform train set\n",
    "X_train = X_train.drop(high_nan_features, axis='columns')\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "\n",
    "# Transform test set\n",
    "X_test = X_test.drop(high_nan_features, axis='columns')\n",
    "print(f'X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-hughes",
   "metadata": {},
   "source": [
    "## Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "interested-crowd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 features with 0 variance.\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator and fit to training data ----------\n",
    "vt = VarianceThreshold(threshold=0)\n",
    "vt.fit(X_train)\n",
    "vt_mask = vt.get_support()   # Returns True for columns that are NOT constant\n",
    "\n",
    "# Print # of constant features\n",
    "print(f'There are {len(X_train.columns) - sum(vt_mask)} features with 0 variance.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informed-vacation",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"normalized_df = X_train / X_train.mean()\\nvt = VarianceThreshold(threshold=(.8*(1-.8)))\\nvt.fit(normalized_df)\\nvt_mask = var_thres.get_support()   # Returns True for columns that are NOT constant\\n\\n# Print # of constant features\\nprint(f'There are {len(normalized_df.columns) - sum(vt_mask)} features with 0 variance.')\\n\\n# Transform training df ----------\\nX_train = X_train.loc[:, vt_mask]\\nprint(f'There are {len(X_train.columns)} features remaining having dropped features with 0 variance.')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalized data approach\n",
    "'''normalized_df = X_train / X_train.mean()\n",
    "vt = VarianceThreshold(threshold=(.8*(1-.8)))\n",
    "vt.fit(normalized_df)\n",
    "vt_mask = var_thres.get_support()   # Returns True for columns that are NOT constant\n",
    "\n",
    "# Print # of constant features\n",
    "print(f'There are {len(normalized_df.columns) - sum(vt_mask)} features with 0 variance.')\n",
    "\n",
    "# Transform training df ----------\n",
    "X_train = X_train.loc[:, vt_mask]\n",
    "print(f'There are {len(X_train.columns)} features remaining having dropped features with 0 variance.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-metadata",
   "metadata": {},
   "source": [
    "**Drop Features Below Variance Threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handmade-brief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (39763, 498)\n",
      "X_test shape: (9941, 498)\n"
     ]
    }
   ],
   "source": [
    "# Transform train set\n",
    "X_train = X_train.loc[:, vt_mask]\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "\n",
    "# Transform test set\n",
    "X_test = X_test.loc[:, vt_mask]\n",
    "print(f'X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-bernard",
   "metadata": {},
   "source": [
    "# Multivariate Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-petite",
   "metadata": {},
   "source": [
    "## Pairwise Correlations\n",
    "* Evaluate correlation between independent variables.\n",
    "* Variable pairs that meet the threshold condition should be tested for correlation with the target variable, the more highly correlated independent variable of the pair should be kept.\n",
    "\n",
    "Vishal Patel suggests threshold of .65.<br>\n",
    "[A Practical Guide to Dimensionality Reduction Techniques](https://www.youtube.com/watch?v=ioXKxulmwVQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-draft",
   "metadata": {},
   "source": [
    "**This function needs to be refined to return variables pairs so they may be tested with the target variable. Remove duplicate pairs of variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "static-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    '''\n",
    "    Iterates through variable pairs and returns set of feature names that are over provided threshold.\n",
    "    '''\n",
    "    col_corr = set()   # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:  # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]   # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dedicated-august",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncorr_matrix = X_train.corr()\\nplt.figure(figsize=(12,10))\\nsns.heatmap(corr_matrix, annot=True, cmap=plt.cm.CMRmap_r)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create correlation matrix and plot heatmap\n",
    "## ----- NOTE: this will not run with too many dimensions. Does not run with sipp2018 ---------\n",
    "'''\n",
    "corr_matrix = X_train.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=plt.cm.CMRmap_r)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sound-attack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 77 pairs of features with a correlation > 0.95.\n"
     ]
    }
   ],
   "source": [
    "# Run correlation test for features\n",
    "corr_threshold = 0.95\n",
    "high_corr_features = correlation(X_train, corr_threshold)\n",
    "print(f'There are {len(high_corr_features)} pairs of features with a correlation > {corr_threshold}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-scene",
   "metadata": {},
   "source": [
    "**Drop Highly Correlated Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "breathing-messenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (39763, 421)\n",
      "X_test shape: (9941, 421)\n"
     ]
    }
   ],
   "source": [
    "# Transform train set\n",
    "X_train = X_train.drop(high_corr_features, axis='columns')\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "\n",
    "# Transform test set\n",
    "X_test = X_test.drop(high_corr_features, axis='columns')\n",
    "print(f'X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-helping",
   "metadata": {},
   "source": [
    "## Correlation w/the Target\n",
    "Drop variables that have a very low correlation with the target.<br>\n",
    "If a variable has a very low correlation w/target it wont be useful for the prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "orange-teddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>EOWN_MF</td>\n",
       "      <td>0.452637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>TVAL_STMF</td>\n",
       "      <td>0.343188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>EOWN_MM</td>\n",
       "      <td>0.336387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>THVAL_STMF</td>\n",
       "      <td>0.309525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>EOWN_IRAKEO</td>\n",
       "      <td>0.305594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>THVAL_RET</td>\n",
       "      <td>0.255799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>TINC_STMF</td>\n",
       "      <td>0.253046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>TVAL_RET</td>\n",
       "      <td>0.249591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>EEDUC_X</td>\n",
       "      <td>0.236743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>TVAL_BANK</td>\n",
       "      <td>0.236125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>TVAL_HOME</td>\n",
       "      <td>0.232405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>TFCYINCPOV</td>\n",
       "      <td>0.226374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>TVAL_AST</td>\n",
       "      <td>0.224541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>EEDUC</td>\n",
       "      <td>0.222781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>EOWN_MCBD</td>\n",
       "      <td>0.222320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>THVAL_BANK</td>\n",
       "      <td>0.220547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>THINC_STMF</td>\n",
       "      <td>0.218569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>TEQ_HOME</td>\n",
       "      <td>0.217219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ENJ_NOWRK4</td>\n",
       "      <td>0.216185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>EOWN_ANNTR</td>\n",
       "      <td>0.210304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>EOWN_CD</td>\n",
       "      <td>0.204985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>THEQ_HOME</td>\n",
       "      <td>0.204496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>TJB1_WKSUM1</td>\n",
       "      <td>0.202820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>THVAL_AST</td>\n",
       "      <td>0.200380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>TFINCPOV</td>\n",
       "      <td>0.193166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        variable  coefficient\n",
       "146      EOWN_MF     0.452637\n",
       "192    TVAL_STMF     0.343188\n",
       "145      EOWN_MM     0.336387\n",
       "224   THVAL_STMF     0.309525\n",
       "151  EOWN_IRAKEO     0.305594\n",
       "236    THVAL_RET     0.255799\n",
       "191    TINC_STMF     0.253046\n",
       "208     TVAL_RET     0.249591\n",
       "420      EEDUC_X     0.236743\n",
       "190    TVAL_BANK     0.236125\n",
       "211    TVAL_HOME     0.232405\n",
       "417   TFCYINCPOV     0.226374\n",
       "220     TVAL_AST     0.224541\n",
       "320        EEDUC     0.222781\n",
       "150    EOWN_MCBD     0.222320\n",
       "222   THVAL_BANK     0.220547\n",
       "223   THINC_STMF     0.218569\n",
       "213     TEQ_HOME     0.217219\n",
       "54    ENJ_NOWRK4     0.216185\n",
       "156   EOWN_ANNTR     0.210304\n",
       "144      EOWN_CD     0.204985\n",
       "243    THEQ_HOME     0.204496\n",
       "123  TJB1_WKSUM1     0.202820\n",
       "249    THVAL_AST     0.200380\n",
       "416     TFINCPOV     0.193166"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with variables and correlation with target \n",
    "y_corr = pd.DataFrame(columns=['variable', 'coefficient'])\n",
    "\n",
    "# Iterate through each column in training set\n",
    "for col in X_train.columns:\n",
    "    y_corr.loc[len(y_corr.index)] = [col, abs(y.corr(X_train[col]))]\n",
    "    \n",
    "y_corr.sort_values(by='coefficient', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-montgomery",
   "metadata": {},
   "source": [
    "Plot the distribution to evaluate a coefficient cutoff for variables to keep or discard.<br>\n",
    "Consider the elbow in the curve and the number of variables retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "based-citizenship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_corr\n",
    "         .sort_values(by='coefficient', ascending=False)\n",
    "         .coefficient\n",
    "         .to_list()\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "earlier-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_corr[y_corr.coefficient >= .2].sort_values(by='coefficient', ascending=False)\n",
    "y_corr_features = y_corr[y_corr.coefficient >= .2].variable.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "driven-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.loc[:,y_corr_features]\n",
    "X_test = X_test.loc[:,y_corr_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "traditional-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features with NA's - go back and impute these\n",
    "X_train = X_train.drop(['ENJ_NOWRK4', 'TJB1_WKSUM1'], axis='columns')\n",
    "X_test = X_test.drop(['ENJ_NOWRK4', 'TJB1_WKSUM1'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "minus-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EOWN_CD</th>\n",
       "      <th>EOWN_MM</th>\n",
       "      <th>EOWN_MF</th>\n",
       "      <th>EOWN_MCBD</th>\n",
       "      <th>EOWN_IRAKEO</th>\n",
       "      <th>EOWN_ANNTR</th>\n",
       "      <th>TVAL_BANK</th>\n",
       "      <th>TINC_STMF</th>\n",
       "      <th>TVAL_STMF</th>\n",
       "      <th>TVAL_RET</th>\n",
       "      <th>...</th>\n",
       "      <th>TVAL_AST</th>\n",
       "      <th>THVAL_BANK</th>\n",
       "      <th>THINC_STMF</th>\n",
       "      <th>THVAL_STMF</th>\n",
       "      <th>THVAL_RET</th>\n",
       "      <th>THEQ_HOME</th>\n",
       "      <th>THVAL_AST</th>\n",
       "      <th>EEDUC</th>\n",
       "      <th>TFCYINCPOV</th>\n",
       "      <th>EEDUC_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47185</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>325550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16800</td>\n",
       "      <td>...</td>\n",
       "      <td>353250</td>\n",
       "      <td>325550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16800</td>\n",
       "      <td>70000</td>\n",
       "      <td>523550</td>\n",
       "      <td>44</td>\n",
       "      <td>3.841</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38713</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>35000</td>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>98440</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16394</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>110750</td>\n",
       "      <td>10500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>288800</td>\n",
       "      <td>39</td>\n",
       "      <td>5.467</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39736</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>56540</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46000</td>\n",
       "      <td>51000</td>\n",
       "      <td>168460</td>\n",
       "      <td>39</td>\n",
       "      <td>2.274</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30473</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16400</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19900</td>\n",
       "      <td>35</td>\n",
       "      <td>1.952</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>63355</td>\n",
       "      <td>1555</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62000</td>\n",
       "      <td>263555</td>\n",
       "      <td>39</td>\n",
       "      <td>1.459</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11190</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>197700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>465300</td>\n",
       "      <td>395400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>650000</td>\n",
       "      <td>500000</td>\n",
       "      <td>51800600</td>\n",
       "      <td>40</td>\n",
       "      <td>13.968</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26569</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13000</td>\n",
       "      <td>...</td>\n",
       "      <td>331750</td>\n",
       "      <td>191500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213000</td>\n",
       "      <td>212000</td>\n",
       "      <td>792500</td>\n",
       "      <td>39</td>\n",
       "      <td>6.526</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9256</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49000</td>\n",
       "      <td>...</td>\n",
       "      <td>122300</td>\n",
       "      <td>4949</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51000</td>\n",
       "      <td>149000</td>\n",
       "      <td>433929</td>\n",
       "      <td>40</td>\n",
       "      <td>8.498</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41555</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>...</td>\n",
       "      <td>5340</td>\n",
       "      <td>45000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40000</td>\n",
       "      <td>0</td>\n",
       "      <td>94510</td>\n",
       "      <td>39</td>\n",
       "      <td>3.903</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39763 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EOWN_CD  EOWN_MM  EOWN_MF  EOWN_MCBD  EOWN_IRAKEO  EOWN_ANNTR  \\\n",
       "47185        2        2        2          2            2           2   \n",
       "38713        2        2        2          2            2           2   \n",
       "16394        2        2        2          2            2           2   \n",
       "39736        2        2        2          2            2           2   \n",
       "30473        2        2        2          2            2           2   \n",
       "...        ...      ...      ...        ...          ...         ...   \n",
       "9704         2        2        2          2            2           2   \n",
       "11190        2        1        1          2            2           2   \n",
       "26569        2        2        2          2            1           1   \n",
       "9256         2        2        2          2            2           2   \n",
       "41555        2        2        2          2            2           2   \n",
       "\n",
       "       TVAL_BANK  TINC_STMF  TVAL_STMF  TVAL_RET  ...  TVAL_AST  THVAL_BANK  \\\n",
       "47185     325550          0          0     16800  ...    353250      325550   \n",
       "38713          0          0          0         0  ...         0        5000   \n",
       "16394       5250          0          0         0  ...    110750       10500   \n",
       "39736        100          0          0         0  ...     56540         220   \n",
       "30473       1500          0          0         0  ...     16400        5000   \n",
       "...          ...        ...        ...       ...  ...       ...         ...   \n",
       "9704        1355          0          0         0  ...     63355        1555   \n",
       "11190     197700          0          0         0  ...    465300      395400   \n",
       "26569     140750          0          0     13000  ...    331750      191500   \n",
       "9256        4300          0          0     49000  ...    122300        4949   \n",
       "41555       2000          0          0      2000  ...      5340       45000   \n",
       "\n",
       "       THINC_STMF  THVAL_STMF  THVAL_RET  THEQ_HOME  THVAL_AST  EEDUC  \\\n",
       "47185           0           0      16800      70000     523550     44   \n",
       "38713           0       35000          0      15000      98440     34   \n",
       "16394           0           0          0      20000     288800     39   \n",
       "39736           0           0      46000      51000     168460     39   \n",
       "30473           0           0          0          0      19900     35   \n",
       "...           ...         ...        ...        ...        ...    ...   \n",
       "9704            0           0          0      62000     263555     39   \n",
       "11190           0           0     650000     500000   51800600     40   \n",
       "26569           0           0     213000     212000     792500     39   \n",
       "9256            0           0      51000     149000     433929     40   \n",
       "41555           0           0      40000          0      94510     39   \n",
       "\n",
       "       TFCYINCPOV  EEDUC_X  \n",
       "47185       3.841       10  \n",
       "38713       0.000        5  \n",
       "16394       5.467        6  \n",
       "39736       2.274        6  \n",
       "30473       1.952        5  \n",
       "...           ...      ...  \n",
       "9704        1.459        6  \n",
       "11190      13.968        7  \n",
       "26569       6.526        6  \n",
       "9256        8.498        7  \n",
       "41555       3.903        6  \n",
       "\n",
       "[39763 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "prescription-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sublime-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Art/Dropbox/My Mac (MacBook-Pro.local)/Documents/Coursework/DS4A/Capstone Project/team_107/team_107_venv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "coordinated-compatibility",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "compound-column",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.91\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "devoted-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 335  841]\n",
      " [  88 8677]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "terminal-paste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-wheat",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team 107 Capstone Project",
   "language": "python",
   "name": "team_107_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
